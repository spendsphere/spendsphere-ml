version: "3.9"

services:
  ml-service:
    build: .
    container_name: spendsphere-ml
    environment:
      - OLLAMA_API_URL=http://host.docker.internal:11434
      - LOG_LEVEL=INFO
    volumes:
      - .:/app
    command: ["python", "src/main.py", "--demo"]

  rabbitmq:
    image: rabbitmq:3.10.7-management
    hostname: rabbitmq
    restart: always
    environment:
      - RABBITMQ_DEFAULT_USER=rmuser
      - RABBITMQ_DEFAULT_PASS=rmpassword
      - RABBITMQ_SERVER_ADDITIONAL_ERL_ARGS=-rabbit log_levels [{connection,error},{default,error}] disk_free_limit 2147483648
    ports:
      - 15673:15672
      - 5673:5672